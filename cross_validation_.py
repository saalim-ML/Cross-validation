# -*- coding: utf-8 -*-
"""Cross Validation .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQ9tDmpMEUTdESoCE7y3hZAo62mUBdyr

# **Cross validation of Heart Disease**

---

---

importing Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

# loading csv data set
heart_data = pd.read_csv('/content/heart_disease_data.csv')

# print first 5 rows of dataset
heart_data.head()

# print last 5 rows of data set
heart_data.tail()

# How many rows and columns
heart_data.shape

# check missing value
heart_data.isnull().sum()

# check distribution of target variable
heart_data['target'].value_counts()   # 1--> defective heart
                                      # 0--> healthy heart

"""spliting x(feature) and y(target)

"""

x = heart_data.drop(columns='target', axis=1)
y = heart_data['target']

# feature variable
print(x)

# target variable
print(y)

"""Train test Split

"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=3, stratify=y)

print(x.shape, x_train.shape, x_test.shape)

"""Comparing the performance of the model list


*   LogisticRegression

*   SVC
*   KNeighborsClassifier
*   RandomForestClassifier


"""

models = [LogisticRegression(max_iter=100000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]

def compare_models_train_test():
  for model in models:
    # training the model
    model.fit(x_train, y_train)
    # evaluating the model
    test_data_prediction= model.predict(x_test)
    accuracy = accuracy_score(y_test, test_data_prediction)
    print('Accuracy score of the ', model, ' = ', accuracy)

compare_models_train_test()

"""**Cross Validation**(cv) K-fold


---



---



"""

cv_score_lr = cross_val_score(LogisticRegression(max_iter=100000), x, y, cv=5)  # lr--> Logistic Rigression
print(cv_score_lr)
mean_accuracy_lr = sum(cv_score_lr)/len(cv_score_lr)
mean_accuracy_lr = mean_accuracy_lr*100
mean_accuracy_lr = round(mean_accuracy_lr, 2)
print(mean_accuracy_lr)

"""S**upport Vector Classifier**(SVC)


---



---


"""

cv_score_svc = cross_val_score(SVC(kernel='linear'), x, y, cv=5)
print(cv_score_svc)
mean_accuracy_svc = sum(cv_score_svc)/len(cv_score_svc)
mean_accuracy_svc = mean_accuracy_svc*100
mean_accuracy_svc = round(mean_accuracy_svc, 2)
print(mean_accuracy_svc)

"""**KNeighborsClassifier**


---



---


"""

cv_score_knn = cross_val_score(KNeighborsClassifier(), x, y, cv=5)
print(cv_score_knn)
mean_accuracy_knn = sum(cv_score_knn)/len(cv_score_knn)
mean_accuracy_knn = mean_accuracy_knn*100
mean_accuracy_knn = round(mean_accuracy_knn, 2)
print(mean_accuracy_knn)

"""**RandomForestClassifier**(RFC)"""

cv_score_rfc = cross_val_score(RandomForestClassifier(), x, y, cv=5)
print(cv_score_rfc)
mean_accuracy_rfc = sum(cv_score_rfc)/len(cv_score_rfc)
mean_accuracy_rfc = mean_accuracy_rfc*100
mean_accuracy_rfc = round(mean_accuracy_rfc, 2)
print(mean_accuracy_rfc)

# list of model
models = [LogisticRegression(max_iter=100000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]

def compare_models_cross_validation():
  for model in models:
    cv_score = cross_val_score(model, x, y, cv=5)
    mean_accuracy = sum(cv_score)/len(cv_score)
    mean_accuracy = mean_accuracy*100
    mean_accuracy = round(mean_accuracy, 2)
    print('Cross Validation accuracies for the ', model, ' = ', cv_score)
    print('Accuracy in % = ', mean_accuracy)
    print('************************************************************************')
compare_models_cross_validation()